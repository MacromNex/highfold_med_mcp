{
  "_description": "Configuration for cyclic peptide model fine-tuning",
  "_source": "Extracted from examples/use_case_4_model_finetuning.py",

  "model": {
    "base_model": "model_2_ptm",
    "model_type": "alphafold",
    "demo_mode": true
  },

  "training": {
    "num_epochs": 10,
    "batch_size": 1,
    "learning_rate": 1e-4,
    "crop_size": null,
    "validation_frequency": 5,
    "save_checkpoints": true,
    "checkpoint_frequency": 5
  },

  "data": {
    "auto_detect_crop_size": true,
    "sequence_column": "target_chainseq",
    "min_sequence_length": 3,
    "max_sequence_length": 50,
    "validation_split": 0.1
  },

  "optimization": {
    "optimizer": "adam",
    "scheduler": "constant",
    "early_stopping": false,
    "patience": 10,
    "min_delta": 0.001
  },

  "losses": {
    "primary_loss": "fape",
    "auxiliary_losses": ["plddt", "distogram"],
    "loss_weights": {
      "fape": 1.0,
      "plddt": 0.1,
      "distogram": 0.05
    }
  },

  "output": {
    "save_training_history": true,
    "save_model_checkpoints": true,
    "save_validation_metrics": true,
    "log_frequency": 1
  },

  "demo": {
    "synthetic_data_samples": 2500,
    "validation_samples": 250,
    "simulate_realistic_losses": true,
    "add_noise_to_progression": true
  }
}